{
    "batch_size": 4,
    "token_dim": 2,
    "learning_rate": 0.0003,
    "weight_decay": 0.0001,
    "attention_dim": 4096,
    "num_attention_heads": 32,
    "embedding_dim": 256,
    "feed_forward_dim": 256,
    "num_blocks": 24,
    "grad_clip": 2.0,
    "remat": false
}
